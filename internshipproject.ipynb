{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86af06a6-af04-48a3-8cac-245663e20dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  TEACHER QUITS JOB After 5th, 6th Grade Muslim ...   \n",
      "1  NC TEACHER SIGNS UP FIRST GRADERS For Black Li...   \n",
      "2  WATCH: TRANS ARTIST DEMONSTRATES How She Colle...   \n",
      "3   London’s New Muslim Mayor Has Some VERY Choic...   \n",
      "4  Top Democrat says not clear if Americans helpe...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  You re never to young to commit jihad Teachers...     left-news   \n",
      "1   This so-called movement is out of control and...     left-news   \n",
      "2  So much hate. So much anger. So much time on t...     left-news   \n",
      "3  While the United States has as one of its pres...          News   \n",
      "4  WASHINGTON (Reuters) - U.S. Representative Ada...  politicsNews   \n",
      "\n",
      "              date  label  \n",
      "0      May 9, 2017      0  \n",
      "1     Mar 17, 2016      0  \n",
      "2     Oct 21, 2017      0  \n",
      "3     May 13, 2016      0  \n",
      "4  March 20, 2017       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fake = pd.read_csv(\"Fake.csv\")\n",
    "real = pd.read_csv(\"True.csv\")\n",
    "\n",
    "# Add labels\n",
    "fake['label'] = 0  # 0 = fake\n",
    "real['label'] = 1  # 1 = real\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([fake, real])\n",
    "\n",
    "# Shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Check data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd73984e-ece2-4cc4-8bce-7a9c09505410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])  # Remove punctuation\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]  # Remove stopwords and stem\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['text'] = data['title'] + \" \" + data['text']  # Combine title and article\n",
    "data['text'] = data['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b632b9-1222-4a05-be6e-769024f131a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    1\n",
      "7    0\n",
      "8    1\n",
      "9    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data['text']).toarray()\n",
    "y = data['label']\n",
    "print(X.shape)      # Shows (number of samples, 5000 features)\n",
    "print(X[:2])        # Shows first 2 rows of TF-IDF matrix\n",
    "print(y[:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b072d0-7552-4162-bded-299fa0f07d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9902004454342984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4640\n",
      "           1       0.99      0.99      0.99      4340\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Try one model\n",
    "model = LogisticRegression()\n",
    "# model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee309d0-afd3-403f-8823-e6b8bfa6604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model and vectorizer\n",
    "pickle.dump(model, open('model.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open('vectorizer.pkl', 'wb'))\n",
    "print(\"✅ Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3912a695-97a0-4b73-8d7e-b88fde8ffc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in current directory:\n",
      "['.anaconda', '.conda', '.condarc', '.continuum', '.ipynb_checkpoints', '.ipython', '.jupyter', '.matplotlib', '.vscode', '3D Objects', 'anaconda3', 'AppData', 'Application Data', 'breast-cancer.csv', 'Contacts', 'Cookies', 'data.csv', 'Desktop', 'Documents', 'Downloads', 'Fake.csv', 'Favorites', 'heart.csv', 'heart_decision_tree', 'IntelGraphicsProfiles', 'Iris.csv', 'iris_tree', 'Links', 'Local Settings', 'Mall_Customers.csv', 'model.pkl', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{c7bd9da4-51c2-11f0-8aaa-f1434417f81f}.TxR.0.regtrans-ms', 'NTUSER.DAT{c7bd9da4-51c2-11f0-8aaa-f1434417f81f}.TxR.1.regtrans-ms', 'NTUSER.DAT{c7bd9da4-51c2-11f0-8aaa-f1434417f81f}.TxR.2.regtrans-ms', 'NTUSER.DAT{c7bd9da4-51c2-11f0-8aaa-f1434417f81f}.TxR.blf', 'NTUSER.DAT{c7bd9da5-51c2-11f0-8aaa-f1434417f81f}.TM.blf', 'NTUSER.DAT{c7bd9da5-51c2-11f0-8aaa-f1434417f81f}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{c7bd9da5-51c2-11f0-8aaa-f1434417f81f}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'Pictures', 'PrintHood', 'Recent', 'Saved Games', 'Searches', 'SendTo', 'Start Menu', 'Task 4', 'Task 5', 'Task 6', 'Task 7', 'Task 8', 'Templates', 'True.csv', 'Untitled.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'Untitled3.ipynb', 'Untitled4.ipynb', 'Untitled5.ipynb', 'Untitled6.ipynb', 'Untitled7.ipynb', 'vectorizer.pkl', 'Videos']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Files in current directory:\")\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f35df-38b5-43bb-b4ef-d3993b20aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d808f1-5915-44f0-b927-ae23ec0b4580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
